Data Source
https://www.kaggle.com/code/sudhanshu2198/multi-class-credit-score-classification/input?select=Score.csv

Introduction:
This report presents the exploratory data analysis (EDA) for a credit score classification problem. The goal is to understand the structure, qualiy and statistical properties of the dataset to inform feature selection and model development in subsequent phases.

1. Data Loading and Initial Inspection
The training, test and the benchmark scoring datasets are imported and examined to uderstand their structure and and valriable types.

```{r}
# Load required libraries
library(tidyverse)
library(janitor)
library(skimr)
library(DataExplorer)
library(corrplot)
library(Amelia)

# Load the data
train <- read.csv("train.csv", stringsAsFactors = TRUE)
test <- read.csv("test.csv", stringsAsFactors = TRUE)
score <- read.csv("Score.csv", stringsAsFactors = TRUE)

# View dimensions
dim(train)
dim(test)
dim(score)

# Quick glimpse
glimpse(train)
```

2. Assessment of missing values
A through check for missing values is conducted to determine the extent and distribution of incompleteness across the dataset
```{r}
colSums(is.na(train))
skim(train)
```

3. Visualise missing values
Yellow represents missing values, and black represents available values. Blocks of missingness in specific columns indicate a need for either targeted imputation or column removal, especially if missingness is extensive or not missing at random (NMAR).
```{r}
library(Amelia)  # For missmap visualization
missmap(train, 
        main = "Missing Values Map", 
        col = c("yellow", "black"), 
        legend = TRUE)      
```

4. Data type correction
Several columns originally read as character variables contain numeric data. These are converted to numeric or categorical types to enable statistical analysis.
```{r}
# Define a function to clean and convert character values to numeric
clean_numeric <- function(x) {
  x <- as.character(x)
  x <- gsub(",", "", x)
  x <- gsub("[$%]", "", x)
  x <- gsub("[^0-9\\.\\-]", "", x)
  suppressWarnings(as.numeric(x))
}

# List of columns expected to be numeric but possibly read as character
cols_to_convert <- c("Age", "Annual_Income", "Outstanding_Debt", "Num_of_Loan", 
                     "Changed_Credit_Limit", "Num_of_Delayed_Payment", 
                     "Amount_invested_monthly", "Monthly_Balance")

# Check which columns exist in the data before applying
cols_to_convert <- intersect(cols_to_convert, colnames(train))

# Apply cleaning function only to existing columns
for (col in cols_to_convert) {
  train[[col]] <- clean_numeric(train[[col]])
}

# Convert these columns to factors only if they exist
if ("Credit_Mix" %in% names(train)) {
  train$Credit_Mix <- as.factor(train$Credit_Mix)
}
if ("Payment_of_Min_Amount" %in% names(train)) {
  train$Payment_of_Min_Amount <- as.factor(train$Payment_of_Min_Amount)
}

# Show summary of the cleaned dataset
summary(train)

 
```

5. Removal of Irrelevant Features
Columns such as identifiers and personal details (Ex: ID, Name, SSN) are removed as they do not contribute predictive value to the modeling task.
```{r}
    colnames(train)

```

6. PCA for visualisation
```{r}

              
```

7. Distribution Plot
```{r}
       
```

```{r}
               
```

```{r}
              
```

```{r}
               
```
```{r}
               # Dimensions (rows, columns)
```

```{r}
               # Dimensions (rows, columns)
```

```{r}
               # Dimensions (rows, columns)
```

```{r}
               # Dimensions (rows, columns)
```